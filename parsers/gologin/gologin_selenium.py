#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Fragrantica Parser —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º GoLogin SDK –∏ Selenium
–û—Å–Ω–æ–≤–∞–Ω –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: https://gologin.com/docs/api-reference/introduction/quickstart
"""

import os
import time
import json
from datetime import datetime
import logging
from typing import List, Dict, Optional
import re
import random
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator

# –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π GoLogin SDK
from gologin import GoLogin
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data/logs/gologin_selenium.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class FragranticaGoLoginSeleniumParser:
    """–ü–∞—Ä—Å–µ—Ä Fragrantica —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º GoLogin SDK –∏ Selenium"""
    
    def __init__(self):
        self.base_url = "https://www.fragrantica.com"
        self.translator = GoogleTranslator(source='en', target='ru')
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GoLogin —Å —Ç–æ–∫–µ–Ω–æ–º –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        self.gl = GoLogin({
            "token": os.environ.get('GL_API_TOKEN', 'your dev token'),
        })
        
        self.driver = None
        self.profile_id = None
        
        logger.info("GoLogin Selenium –ø–∞—Ä—Å–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def create_profile(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è —Å —Å–ª—É—á–∞–π–Ω—ã–º fingerprint"""
        try:
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å —Å Windows OS
            profile = self.gl.createProfileRandomFingerprint({ "os": "win" })
            self.profile_id = profile.get('id')
            
            # –î–æ–±–∞–≤–ª—è–µ–º US –ø—Ä–æ–∫—Å–∏ –∫ –ø—Ä–æ—Ñ–∏–ª—é
            self.gl.addGologinProxyToProfile(self.profile_id, "us")
            
            logger.info(f"–°–æ–∑–¥–∞–Ω –ø—Ä–æ—Ñ–∏–ª—å GoLogin: {self.profile_id}")
            return self.profile_id
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–æ—Ñ–∏–ª—è: {e}")
            raise
    
    def start_browser(self):
        """–ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞ —á–µ—Ä–µ–∑ GoLogin"""
        try:
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º ID –ø—Ä–æ—Ñ–∏–ª—è
            self.gl.setProfileId(self.profile_id)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –±—Ä–∞—É–∑–µ—Ä –∏ –ø–æ–ª—É—á–∞–µ–º WebSocket URL
            debugger_address = self.gl.start()
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏—é Chromium –¥–ª—è webdriver
            chromium_version = self.gl.get_chromium_version()
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º webdriver
            service = Service(ChromeDriverManager(driver_version=chromium_version).install())
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Chrome
            chrome_options = webdriver.ChromeOptions()
            chrome_options.add_experimental_option("debuggerAddress", debugger_address)
            
            # –°–æ–∑–¥–∞–µ–º –¥—Ä–∞–π–≤–µ—Ä
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–∞–π–º–∞—É—Ç–æ–≤
            self.driver.implicitly_wait(10)
            self.driver.set_page_load_timeout(30)
            
            logger.info("–ë—Ä–∞—É–∑–µ—Ä GoLogin –∑–∞–ø—É—â–µ–Ω")
            return self.driver
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±—Ä–∞—É–∑–µ—Ä–∞: {e}")
            raise
    
    def get_page_content(self, url: str) -> Optional[BeautifulSoup]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            logger.info(f"–ó–∞–≥—Ä—É–∂–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")
            
            # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
            self.driver.get(url)
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            WebDriverWait(self.driver, 30).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
            time.sleep(5)
            
            # –ü–æ–ª—É—á–∞–µ–º HTML
            page_source = self.driver.page_source
            
            # –ü–∞—Ä—Å–∏–º HTML
            soup = BeautifulSoup(page_source, 'html.parser')
            return soup
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}")
            return None
    
    def extract_news_from_main_page(self) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        logger.info("–ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã Fragrantica...")
        
        soup = self.get_page_content(self.base_url)
        if not soup:
            return []
        
        news_items = []
        
        # –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤
        news_boxes = soup.find_all('div', class_='fr-news-box')
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(news_boxes)} –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤")
        
        for i, news_box in enumerate(news_boxes[:5], 1):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 5 –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏
            try:
                news_item = self._extract_news_data(news_box)
                if news_item and news_item.get('link'):
                    logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –Ω–æ–≤–æ—Å—Ç—å {i}: {news_item.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞')}")
                    
                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏
                    full_content = self._get_article_content_safely(news_item['link'])
                    if full_content:
                        news_item['full_content'] = full_content
                        news_item['full_content_ru'] = self.translate_text(full_content)
                    
                    news_items.append(news_item)
                    
                    # –£–º–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    time.sleep(random.uniform(2, 4))
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–æ–≤–æ—Å—Ç–∏ {i}: {e}")
                continue
        
        logger.info(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        return news_items
    
    def _extract_news_data(self, news_box) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –±–ª–æ–∫–∞"""
        try:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title_elem = news_box.find('h3')
            title = title_elem.get_text(strip=True) if title_elem else "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"
            
            # –°—Å—ã–ª–∫–∞
            link_elem = news_box.find('a')
            link = link_elem.get('href') if link_elem else None
            if link and not link.startswith('http'):
                link = self.base_url + link
            
            # –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            content_elem = news_box.find(['p', 'div'])
            content = content_elem.get_text(strip=True) if content_elem else ""
            
            # –î–∞—Ç–∞
            date_elem = news_box.find('time')
            date = date_elem.get_text(strip=True) if date_elem else datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            return {
                'title': title,
                'link': link,
                'content': content,
                'date': date
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–∏: {e}")
            return None
    
    def _get_article_content_safely(self, article_url: str) -> Optional[str]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Å—Ç–∞—Ç—å–∏"""
        try:
            logger.info(f"–ü–æ–ª—É—á–∞—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏: {article_url}")
            
            soup = self.get_page_content(article_url)
            if not soup:
                return None
            
            return self._extract_article_content(soup)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Å—Ç–∞—Ç—å–∏ {article_url}: {e}")
            return None
    
    def _extract_article_content(self, soup: BeautifulSoup) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏ –∏–∑ HTML"""
        try:
            # –°–ø–∏—Å–æ–∫ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            content_selectors = [
                'div.article-content',
                'div.post-content',
                'div.entry-content',
                'div.content',
                'article .content',
                '.main-content',
                '.article-body',
                '.post-body',
                '.news-content',
                '.article-text',
                '.post-text',
                '.entry-content',
                '.content-area',
                '.article',
                '.post',
                '.entry'
            ]
            
            # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
            for selector in content_selectors:
                content_elem = soup.select_one(selector)
                if content_elem:
                    # –û—á–∏—â–∞–µ–º HTML –æ—Ç —Å–∫—Ä–∏–ø—Ç–æ–≤ –∏ —Å—Ç–∏–ª–µ–π
                    for script in content_elem(["script", "style"]):
                        script.decompose()
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç
                    text = content_elem.get_text(separator='\n', strip=True)
                    
                    # –û—á–∏—â–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
                    text = re.sub(r'\n\s*\n', '\n\n', text)
                    text = re.sub(r' +', ' ', text)
                    
                    if text.strip():
                        logger.info(f"–ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                        return text.strip()
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç, –±–µ—Ä–µ–º –≤–µ—Å—å body
            body = soup.find('body')
            if body:
                # –£–¥–∞–ª—è–µ–º –Ω–∞–≤–∏–≥–∞—Ü–∏—é, —Ñ—É—Ç–µ—Ä –∏ –¥—Ä—É–≥–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                for elem in body(['nav', 'header', 'footer', 'aside', 'script', 'style']):
                    elem.decompose()
                
                text = body.get_text(separator='\n', strip=True)
                text = re.sub(r'\n\s*\n', '\n\n', text)
                text = re.sub(r' +', ' ', text)
                
                return text.strip()
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏: {e}")
            return None
    
    def translate_text(self, text: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–π"""
        try:
            if not text or len(text.strip()) < 10:
                return ""
            
            return self.translator.translate(text)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Ç–µ–∫—Å—Ç–∞: {e}")
            return ""
    
    def translate_news(self, news_items: List[Dict]) -> List[Dict]:
        """–ü–µ—Ä–µ–≤–æ–¥ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ä—É—Å—Å–∫–∏–π"""
        logger.info("–ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–≤–æ–¥ –Ω–æ–≤–æ—Å—Ç–µ–π...")
        
        for i, news_item in enumerate(news_items, 1):
            try:
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                if news_item.get('title'):
                    news_item['title_ru'] = self.translate_text(news_item['title'])
                
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
                if news_item.get('content'):
                    news_item['content_ru'] = self.translate_text(news_item['content'])
                
                logger.info(f"–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å {i}/{len(news_items)}")
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –Ω–æ–≤–æ—Å—Ç–∏ {i}: {e}")
                continue
        
        return news_items
    
    def save_to_json(self, news_items: List[Dict], filename: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"data/output/fragrantica_gologin_selenium_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(news_items, f, ensure_ascii=False, indent=2)
            
            logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ JSON: {e}")
            return None
    
    def print_news_summary(self, news_items: List[Dict]):
        """–í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        print(f"\nüì∞ –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(news_items)}")
        
        for i, item in enumerate(news_items, 1):
            print(f"\n{i}. {item.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞')}")
            print(f"   üìÖ {item.get('date', '–ë–µ–∑ –¥–∞—Ç—ã')}")
            print(f"   üîó {item.get('link', '–ë–µ–∑ —Å—Å—ã–ª–∫–∏')}")
            
            content = item.get('content', '')
            if content:
                print(f"   üìù {content[:100]}{'...' if len(content) > 100 else ''}")
            
            full_content = item.get('full_content', '')
            if full_content:
                print(f"   üìÑ –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(full_content)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            if self.driver:
                self.driver.quit()
                logger.info("–ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
            
            if self.profile_id:
                self.gl.delete(self.profile_id)
                logger.info(f"–ü—Ä–æ—Ñ–∏–ª—å {self.profile_id} —É–¥–∞–ª–µ–Ω")
            
            self.gl.stop()
            logger.info("GoLogin –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {e}")
    
    def run(self, news_count: int = 3):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞"""
        try:
            logger.info("üöÄ –ó–∞–ø—É—Å–∫ GoLogin Selenium –ø–∞—Ä—Å–µ—Ä–∞ Fragrantica...")
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å
            self.create_profile()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
            self.start_browser()
            
            # –ü–∞—Ä—Å–∏–º –Ω–æ–≤–æ—Å—Ç–∏
            news_items = self.extract_news_from_main_page()
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π
            news_items = news_items[:news_count]
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–æ–≤–æ—Å—Ç–∏
            news_items = self.translate_news(news_items)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            filename = self.save_to_json(news_items)
            
            # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
            self.print_news_summary(news_items)
            
            logger.info("‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            return news_items
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
            return []
        
        finally:
            self.cleanup()

def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    parser = FragranticaGoLoginSeleniumParser()
    
    try:
        news_items = parser.run(news_count=3)
        
        if news_items:
            print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        else:
            print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏")
            
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main() 