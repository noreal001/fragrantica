#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π GoLogin –ø–∞—Ä—Å–µ—Ä —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º API –ø–æ–¥—Ö–æ–¥–æ–º
"""

import time
import json
from datetime import datetime
from deep_translator import GoogleTranslator
import logging
import requests
from bs4 import BeautifulSoup
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleGoLoginParser:
    def __init__(self):
        self.base_url = "https://www.fragrantica.com"
        self.translator = GoogleTranslator(source='en', target='ru')
        self.gologin_token = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiI2ODhmMWM3ZDMwMmNjMjU3OGRmMDJkYzEiLCJ0eXBlIjoiZGV2Iiwiand0aWQiOiI2ODhmMWQxNTMwMmNjMjU3OGRmMGQ2M2IifQ.ZqTJqaxx5AFA5-mLWiAtBa0y5sat4lL1ttNFuq93kqM"
        self.api_url = "https://api.gologin.com"
    
    def _create_profile(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è —á–µ—Ä–µ–∑ GoLogin API"""
        try:
            profile_data = {
                "name": f"fragrantica_parser_{int(time.time())}",
                "notes": "–ü–∞—Ä—Å–µ—Ä Fragrantica",
                "navigator": {
                    "language": ["en-US", "en"],
                    "userAgent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                    "resolution": "1920x1080",
                    "platform": "MacIntel"
                }
            }
            
            headers = {
                'Authorization': f'Bearer {self.gologin_token}',
                'Content-Type': 'application/json'
            }
            
            response = requests.post(
                f"{self.api_url}/browser",
                json=profile_data,
                headers=headers
            )
            
            if response.status_code == 200:
                profile = response.json()
                logger.info(f"–°–æ–∑–¥–∞–Ω –ø—Ä–æ—Ñ–∏–ª—å: {profile['id']}")
                return profile['id']
            else:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è: {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–æ—Ñ–∏–ª—è: {e}")
            return None
    
    def _get_page_content(self, url):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏"""
        try:
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9,ru;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'Cache-Control': 'max-age=0'
            })
            
            response = session.get(url, timeout=30)
            response.raise_for_status()
            
            return response.text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}")
            return None
    
    def extract_news(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        logger.info("–ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å
        profile_id = self._create_profile()
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            page_content = self._get_page_content(self.base_url)
            if not page_content:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É")
                return []
            
            soup = BeautifulSoup(page_content, 'html.parser')
            news_items = []
            
            # –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤
            news_boxes = soup.find_all('div', class_='fr-news-box')
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(news_boxes)} –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤")
            
            for i, news_box in enumerate(news_boxes[:3], 1):
                try:
                    news_item = self._extract_news_data(news_box)
                    if news_item and news_item.get('link'):
                        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏
                        full_content = self._get_article_content(news_item['link'])
                        if full_content:
                            news_item['full_content'] = full_content
                            news_item['full_content_ru'] = self.translate_text(full_content)
                        
                        news_items.append(news_item)
                        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å {i}: {news_item.get('title', '')[:50]}...")
                        
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–æ–≤–æ—Å—Ç–∏ {i}: {e}")
                    continue
            
            return news_items
            
        finally:
            if profile_id:
                self._delete_profile(profile_id)
    
    def _extract_news_data(self, news_box):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –±–ª–æ–∫–∞"""
        try:
            title_elem = news_box.find('h3')
            title = title_elem.get_text(strip=True) if title_elem else ""
            
            link_elem = news_box.find('a')
            link = ""
            if link_elem and link_elem.get('href'):
                href = link_elem.get('href')
                link = self.base_url + href if href.startswith('/') else href
            
            content_elem = news_box.find(['p', 'div'], class_=re.compile(r'content|description|excerpt', re.I))
            if not content_elem:
                content_elem = news_box.find('p')
            content = content_elem.get_text(strip=True) if content_elem else ""
            
            if title:
                return {
                    'title': title,
                    'link': link,
                    'content': content,
                    'date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'original_language': 'en'
                }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–∏: {e}")
        
        return None
    
    def _get_article_content(self, article_url):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Å—Ç–∞—Ç—å–∏"""
        try:
            logger.info(f"–ü–æ–ª—É—á–∞—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏: {article_url}")
            
            page_content = self._get_page_content(article_url)
            if not page_content:
                return None
            
            soup = BeautifulSoup(page_content, 'html.parser')
            
            # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            content_selectors = [
                'div.article-content',
                'div.post-content',
                'div.entry-content',
                'div.content',
                'article .content',
                '.main-content',
                '.article-body',
                '.post-body',
                '.news-content'
            ]
            
            for selector in content_selectors:
                content_elem = soup.select_one(selector)
                if content_elem:
                    for script in content_elem(["script", "style", "nav", "header", "footer"]):
                        script.decompose()
                    
                    text = content_elem.get_text(separator='\n', strip=True)
                    if text and len(text) > 200:
                        text = re.sub(r'\n\s*\n', '\n\n', text)
                        text = re.sub(r'\s+', ' ', text)
                        return text.strip()
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—â–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
            paragraphs = soup.find_all('p')
            if paragraphs:
                texts = [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True) and len(p.get_text(strip=True)) > 50]
                return '\n\n'.join(texts)
            
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}")
            return None
    
    def translate_text(self, text):
        """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–π"""
        try:
            if not text or len(text.strip()) < 10:
                return ""
            
            return self.translator.translate(text)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Ç–µ–∫—Å—Ç–∞: {e}")
            return ""
    
    def translate_news(self, news_items):
        """–ü–µ—Ä–µ–≤–æ–¥ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        logger.info("–ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–≤–æ–¥ –Ω–æ–≤–æ—Å—Ç–µ–π...")
        
        for i, news_item in enumerate(news_items, 1):
            try:
                if news_item.get('title'):
                    news_item['title_ru'] = self.translate_text(news_item['title'])
                
                if news_item.get('content'):
                    news_item['content_ru'] = self.translate_text(news_item['content'])
                
                logger.info(f"–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å {i}/{len(news_items)}")
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –Ω–æ–≤–æ—Å—Ç–∏ {i}: {e}")
                continue
        
        return news_items
    
    def _delete_profile(self, profile_id):
        """–£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è"""
        try:
            headers = {
                'Authorization': f'Bearer {self.gologin_token}',
                'Content-Type': 'application/json'
            }
            
            response = requests.delete(
                f"{self.api_url}/browser/{profile_id}",
                headers=headers
            )
            
            if response.status_code == 200:
                logger.info(f"–ü—Ä–æ—Ñ–∏–ª—å {profile_id} —É–¥–∞–ª–µ–Ω")
            else:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª—å {profile_id}")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –ø—Ä–æ—Ñ–∏–ª—è: {e}")
    
    def save_to_json(self, news_items, filename=None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"fragrantica_simple_news_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(news_items, f, ensure_ascii=False, indent=2)
            
            logger.info(f"–ù–æ–≤–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
            return None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        print("üöÄ –ó–∞–ø—É—Å–∫ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ GoLogin –ø–∞—Ä—Å–µ—Ä–∞...")
        
        parser = SimpleGoLoginParser()
        
        # –ü–∞—Ä—Å–∏–º –Ω–æ–≤–æ—Å—Ç–∏
        news_items = parser.extract_news()
        
        if not news_items:
            print("‚ùå –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–æ–≤–æ—Å—Ç–∏
        news_items = parser.translate_news(news_items)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        filename = parser.save_to_json(news_items)
        
        print(f"\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω! –§–∞–π–ª: {filename}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main() 